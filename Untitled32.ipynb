{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from statsmodels.nonparametric import smoothers_lowess\n",
    "from pandas import Series, DataFrame\n",
    "from patsy import dmatrices\n",
    "from sklearn import datasets, svm\n",
    "from KaggleAux import predict as ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df = df.drop(['Ticket','Cabin'], axis=1)\n",
    "# Remove NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6), dpi=1600) \n",
    "alpha=alpha_scatterplot = 0.2 \n",
    "alpha_bar_chart = 0.55\n",
    "\n",
    "# lets us plot many diffrent shaped graphs together \n",
    "ax1 = plt.subplot2grid((2,3),(0,0))\n",
    "# plots a bar graph of those who surived vs those who did not.               \n",
    "df.Survived.value_counts().plot(kind='bar', alpha=alpha_bar_chart)\n",
    "# this nicely sets the margins in matplotlib to deal with a recent bug 1.3.1\n",
    "ax1.set_xlim(-1, 2)\n",
    "# puts a title on our graph\n",
    "plt.title(\"Distribution of Survival, (1 = Survived)\")    \n",
    "\n",
    "plt.subplot2grid((2,3),(0,1))\n",
    "plt.scatter(df.Survived, df.Age, alpha=alpha_scatterplot)\n",
    "# sets the y axis lable\n",
    "plt.ylabel(\"Age\")\n",
    "# formats the grid line style of our graphs                          \n",
    "plt.grid(b=True, which='major', axis='y')  \n",
    "plt.title(\"Survival by Age,  (1 = Survived)\")\n",
    "\n",
    "ax3 = plt.subplot2grid((2,3),(0,2))\n",
    "df.Pclass.value_counts().plot(kind=\"barh\", alpha=alpha_bar_chart)\n",
    "ax3.set_ylim(-1, len(df.Pclass.value_counts()))\n",
    "plt.title(\"Class Distribution\")\n",
    "\n",
    "plt.subplot2grid((2,3),(1,0), colspan=2)\n",
    "# plots a kernel density estimate of the subset of the 1st class passangers's age\n",
    "df.Age[df.Pclass == 1].plot(kind='kde')    \n",
    "df.Age[df.Pclass == 2].plot(kind='kde')\n",
    "df.Age[df.Pclass == 3].plot(kind='kde')\n",
    " # plots an axis lable\n",
    "plt.xlabel(\"Age\")    \n",
    "plt.title(\"Age Distribution within classes\")\n",
    "# sets our legend for our graph.\n",
    "plt.legend(('1st Class', '2nd Class','3rd Class'),loc='best') \n",
    "\n",
    "ax5 = plt.subplot2grid((2,3),(1,2))\n",
    "df.Embarked.value_counts().plot(kind='bar', alpha=alpha_bar_chart)\n",
    "ax5.set_xlim(-1, len(df.Embarked.value_counts()))\n",
    "# specifies the parameters of our graphs\n",
    "plt.title(\"Passengers per boarding location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "fig, ax = plt.subplots()\n",
    "df.Survived.value_counts().plot(kind='barh', color=\"blue\", alpha=.65)\n",
    "ax.set_ylim(-1, len(df.Survived.value_counts())) \n",
    "plt.title(\"Survival Breakdown (1 = Survived, 0 = Died)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "\n",
    "#create a plot of two subsets, male and female, of the survived variable.\n",
    "#After we do that we call value_counts() so it can be easily plotted as a bar graph. \n",
    "#'barh' is just a horizontal bar graph\n",
    "df_male = df.Survived[df.Sex == 'male'].value_counts().sort_index()\n",
    "df_female = df.Survived[df.Sex == 'female'].value_counts().sort_index()\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "df_male.plot(kind='barh',label='Male', alpha=0.55)\n",
    "df_female.plot(kind='barh', color='#FA2379',label='Female', alpha=0.55)\n",
    "plt.title(\"Who Survived? with respect to Gender, (raw value counts) \"); plt.legend(loc='best')\n",
    "ax1.set_ylim(-1, 2) \n",
    "\n",
    "#adjust graph to display the proportions of survival by gender\n",
    "ax2 = fig.add_subplot(122)\n",
    "(df_male/float(df_male.sum())).plot(kind='barh',label='Male', alpha=0.55)  \n",
    "(df_female/float(df_female.sum())).plot(kind='barh', color='#FA2379',label='Female', alpha=0.55)\n",
    "plt.title(\"Who Survived proportionally? with respect to Gender\"); plt.legend(loc='best')\n",
    "\n",
    "ax2.set_ylim(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,4), dpi=1600)\n",
    "alpha_level = 0.65\n",
    "\n",
    "# building on the previous code, here we create an additional subset with in the gender subset \n",
    "# we created for the survived variable. I know, thats a lot of subsets. After we do that we call \n",
    "# value_counts() so it it can be easily plotted as a bar graph. this is repeated for each gender \n",
    "# class pair.\n",
    "ax1=fig.add_subplot(141)\n",
    "female_highclass = df.Survived[df.Sex == 'female'][df.Pclass != 3].value_counts()\n",
    "female_highclass.plot(kind='bar', label='female, highclass', color='#FA2479', alpha=alpha_level)\n",
    "ax1.set_xticklabels([\"Survived\", \"Died\"], rotation=0)\n",
    "ax1.set_xlim(-1, len(female_highclass))\n",
    "plt.title(\"Who Survived? with respect to Gender and Class\"); plt.legend(loc='best')\n",
    "\n",
    "ax2=fig.add_subplot(142, sharey=ax1)\n",
    "female_lowclass = df.Survived[df.Sex == 'female'][df.Pclass == 3].value_counts()\n",
    "female_lowclass.plot(kind='bar', label='female, low class', color='pink', alpha=alpha_level)\n",
    "ax2.set_xticklabels([\"Died\",\"Survived\"], rotation=0)\n",
    "ax2.set_xlim(-1, len(female_lowclass))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "ax3=fig.add_subplot(143, sharey=ax1)\n",
    "male_lowclass = df.Survived[df.Sex == 'male'][df.Pclass == 3].value_counts()\n",
    "male_lowclass.plot(kind='bar', label='male, low class',color='lightblue', alpha=alpha_level)\n",
    "ax3.set_xticklabels([\"Died\",\"Survived\"], rotation=0)\n",
    "ax3.set_xlim(-1, len(male_lowclass))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "ax4=fig.add_subplot(144, sharey=ax1)\n",
    "male_highclass = df.Survived[df.Sex == 'male'][df.Pclass != 3].value_counts()\n",
    "male_highclass.plot(kind='bar', label='male, highclass', alpha=alpha_level, color='steelblue')\n",
    "ax4.set_xticklabels([\"Died\",\"Survived\"], rotation=0)\n",
    "ax4.set_xlim(-1, len(male_highclass))\n",
    "plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,12), dpi=1600)\n",
    "a = 0.65\n",
    "# Step 1\n",
    "ax1 = fig.add_subplot(341)\n",
    "df.Survived.value_counts().plot(kind='bar', color=\"blue\", alpha=a)\n",
    "ax1.set_xlim(-1, len(df.Survived.value_counts()))\n",
    "plt.title(\"Step. 1\")\n",
    "\n",
    "# Step 2\n",
    "ax2 = fig.add_subplot(345)\n",
    "df.Survived[df.Sex == 'male'].value_counts().plot(kind='bar',label='Male')\n",
    "df.Survived[df.Sex == 'female'].value_counts().plot(kind='bar', color='#FA2379',label='Female')\n",
    "ax2.set_xlim(-1, 2)\n",
    "plt.title(\"Step. 2 \\nWho Survived? with respect to Gender.\"); plt.legend(loc='best')\n",
    "\n",
    "ax3 = fig.add_subplot(346)\n",
    "(df.Survived[df.Sex == 'male'].value_counts()/float(df.Sex[df.Sex == 'male'].size)).plot(kind='bar',label='Male')\n",
    "(df.Survived[df.Sex == 'female'].value_counts()/float(df.Sex[df.Sex == 'female'].size)).plot(kind='bar', color='#FA2379',label='Female')\n",
    "ax3.set_xlim(-1,2)\n",
    "plt.title(\"Who Survied proportionally?\"); plt.legend(loc='best')\n",
    "\n",
    "\n",
    "# Step 3\n",
    "ax4 = fig.add_subplot(349)\n",
    "female_highclass = df.Survived[df.Sex == 'female'][df.Pclass != 3].value_counts()\n",
    "female_highclass.plot(kind='bar', label='female highclass', color='#FA2479', alpha=a)\n",
    "ax4.set_xticklabels([\"Survived\", \"Died\"], rotation=0)\n",
    "ax4.set_xlim(-1, len(female_highclass))\n",
    "plt.title(\"Who Survived? with respect to Gender and Class\"); plt.legend(loc='best')\n",
    "\n",
    "ax5 = fig.add_subplot(3,4,10, sharey=ax1)\n",
    "female_lowclass = df.Survived[df.Sex == 'female'][df.Pclass == 3].value_counts()\n",
    "female_lowclass.plot(kind='bar', label='female, low class', color='pink', alpha=a)\n",
    "ax5.set_xticklabels([\"Died\",\"Survived\"], rotation=0)\n",
    "ax5.set_xlim(-1, len(female_lowclass))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "ax6 = fig.add_subplot(3,4,11, sharey=ax1)\n",
    "male_lowclass = df.Survived[df.Sex == 'male'][df.Pclass == 3].value_counts()\n",
    "male_lowclass.plot(kind='bar', label='male, low class',color='lightblue', alpha=a)\n",
    "ax6.set_xticklabels([\"Died\",\"Survived\"], rotation=0)\n",
    "ax6.set_xlim(-1, len(male_lowclass))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "ax7 = fig.add_subplot(3,4,12, sharey=ax1)\n",
    "male_highclass = df.Survived[df.Sex == 'male'][df.Pclass != 3].value_counts()\n",
    "male_highclass.plot(kind='bar', label='male highclass', alpha=a, color='steelblue')\n",
    "ax7.set_xticklabels([\"Died\",\"Survived\"], rotation=0)\n",
    "ax7.set_xlim(-1, len(male_highclass))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model formula\n",
    "# here the ~ sign is an = sign, and the features of our dataset\n",
    "# are written as a formula to predict survived. The C() lets our \n",
    "# regression know that those variables are categorical.\n",
    "# Ref: http://patsy.readthedocs.org/en/latest/formulas.html\n",
    "formula = 'Survived ~ C(Pclass) + C(Sex) + Age + SibSp  + C(Embarked)' \n",
    "# create a results dictionary to hold our regression results for easy analysis later        \n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a regression friendly dataframe using patsy's dmatrices function\n",
    "y,x = dmatrices(formula, data=df, return_type='dataframe')\n",
    "\n",
    "# instantiate our model\n",
    "model = sm.Logit(y,x)\n",
    "\n",
    "# fit our model to the training data\n",
    "res = model.fit()\n",
    "\n",
    "# save the result for outputing predictions later\n",
    "results['Logit'] = [res, formula]\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4));\n",
    "plt.subplot(121, axisbg=\"#DBDBDB\")\n",
    "# generate predictions from our fitted model\n",
    "ypred = res.predict(x)\n",
    "plt.plot(x.index, ypred, 'bo', x.index, y, 'mo', alpha=.25);\n",
    "plt.grid(color='white', linestyle='dashed')\n",
    "plt.title('Logit predictions, Blue: \\nFitted/predicted values: Red');\n",
    "\n",
    "# Residuals\n",
    "ax2 = plt.subplot(122, axisbg=\"#DBDBDB\")\n",
    "plt.plot(res.resid_dev, 'r-')\n",
    "plt.grid(color='white', linestyle='dashed')\n",
    "ax2.set_xlim(-1, len(res.resid_dev))\n",
    "plt.title('Logit Residuals');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,9), dpi=1600)\n",
    "a = .2\n",
    "\n",
    "# Below are examples of more advanced plotting. \n",
    "# It it looks strange check out the tutorial above.\n",
    "fig.add_subplot(221, axisbg=\"#DBDBDB\")\n",
    "kde_res = KDEUnivariate(res.predict())\n",
    "kde_res.fit()\n",
    "plt.plot(kde_res.support,kde_res.density)\n",
    "plt.fill_between(kde_res.support,kde_res.density, alpha=a)\n",
    "plt.title(\"Distribution of our Predictions\")\n",
    "\n",
    "fig.add_subplot(222, axisbg=\"#DBDBDB\")\n",
    "plt.scatter(res.predict(),x['C(Sex)[T.male]'] , alpha=a)\n",
    "plt.grid(b=True, which='major', axis='x')\n",
    "plt.xlabel(\"Predicted chance of survival\")\n",
    "plt.ylabel(\"Gender Bool\")\n",
    "plt.title(\"The Change of Survival Probability by Gender (1 = Male)\")\n",
    "\n",
    "fig.add_subplot(223, axisbg=\"#DBDBDB\")\n",
    "plt.scatter(res.predict(),x['C(Pclass)[T.3]'] , alpha=a)\n",
    "plt.xlabel(\"Predicted chance of survival\")\n",
    "plt.ylabel(\"Class Bool\")\n",
    "plt.grid(b=True, which='major', axis='x')\n",
    "plt.title(\"The Change of Survival Probability by Lower Class (1 = 3rd Class)\")\n",
    "\n",
    "fig.add_subplot(224, axisbg=\"#DBDBDB\")\n",
    "plt.scatter(res.predict(),x.Age , alpha=a)\n",
    "plt.grid(True, linewidth=0.15)\n",
    "plt.title(\"The Change of Survival Probability by Age\")\n",
    "plt.xlabel(\"Predicted chance of survival\")\n",
    "plt.ylabel(\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Survived'] = 1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compared_resuts = ka.predict(test_data, results, 'Logit')\n",
    "compared_resuts = Series(compared_resuts)  # convert our model to a series for easy output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compared_resuts.to_csv(\"data/output/logitregres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_ml = 'Survived ~ C(Pclass) + C(Sex) + Age + SibSp + Parch + C(Embarked)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plotting parameters\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# create a regression friendly data frame\n",
    "y, x = dmatrices(formula_ml, data=df, return_type='matrix')\n",
    "\n",
    "# select which features we would like to analyze\n",
    "# try chaning the selection here for diffrent output.\n",
    "# Choose : [2,3] - pretty sweet DBs [3,1] --standard DBs [7,3] -very cool DBs,\n",
    "# [3,6] -- very long complex dbs, could take over an hour to calculate! \n",
    "feature_1 = 2\n",
    "feature_2 = 3\n",
    "\n",
    "X = np.asarray(x)\n",
    "X = X[:,[feature_1, feature_2]]  \n",
    "\n",
    "\n",
    "y = np.asarray(y)\n",
    "# needs to be 1 dimenstional so we flatten. it comes out of dmatirces with a shape. \n",
    "y = y.flatten()      \n",
    "\n",
    "n_sample = len(X)\n",
    "\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_sample)\n",
    "\n",
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "\n",
    "# do a cross validation\n",
    "nighty_precent_of_sample = int(.9 * n_sample)\n",
    "X_train = X[:nighty_precent_of_sample]\n",
    "y_train = y[:nighty_precent_of_sample]\n",
    "X_test = X[nighty_precent_of_sample:]\n",
    "y_test = y[nighty_precent_of_sample:]\n",
    "\n",
    "# create a list of the types of kerneks we will use for your analysis\n",
    "types_of_kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "# specify our color map for plotting the results\n",
    "color_map = plt.cm.RdBu_r\n",
    "\n",
    "# fit the model\n",
    "for fig_num, kernel in enumerate(types_of_kernels):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=color_map)\n",
    "\n",
    "    # circle out the test data\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], s=80, facecolors='none', zorder=10)\n",
    "    \n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=color_map)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "               levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can output which ever result you would like by changing the Kernel and clf.predict lines\n",
    "# Change kernel here to poly, rbf or linear\n",
    "# adjusting the gamma level also changes the degree to which the model is fitted\n",
    "clf = svm.SVC(kernel='poly', gamma=3).fit(X_train, y_train)                                                            \n",
    "y,x = dmatrices(formula_ml, data=test_data, return_type='dataframe')\n",
    "\n",
    "# Change the interger values within x.ix[:,[6,3]].dropna() explore the relationships between other \n",
    "# features. the ints are column postions. ie. [6,3] 6th column and the third column are evaluated. \n",
    "res_svm = clf.predict(x.ix[:,[6,3]].dropna()) \n",
    "\n",
    "res_svm = DataFrame(res_svm,columns=['Survived'])\n",
    "res_svm.to_csv(\"data/output/svm_poly_63_g10.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the machine learning library that holds the randomforest\n",
    "import sklearn.ensemble as ske\n",
    "http://localhost:8888/notebooks/Untitled32.ipynb?kernel_name=python3#\n",
    "# Create the random forest model and fit the model to our training data\n",
    "y, x = dmatrices(formula_ml, data=df, return_type='dataframe')\n",
    "# RandomForestClassifier expects a 1 demensional NumPy array, so we convert\n",
    "y = np.asarray(y).ravel()\n",
    "#instantiate and fit our model\n",
    "results_rf = ske.RandomForestClassifier(n_estimators=100).fit(x, y)\n",
    "\n",
    "# Score the results\n",
    "score = results_rf.score(x, y)\n",
    "print \"Mean accuracy of Random Forest Predictions on the data was: {0}\".format(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
